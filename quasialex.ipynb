{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doranosu/alex/blob/main/quasialex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_oTaGI9jT5v",
        "outputId": "06673194-60b3-433e-d834-d1590939b19c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 3, 32, 32)\n",
            "(50000,)\n",
            "(10000, 3, 32, 32)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data/', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data/', train=False, transform=transform, download=True)\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for img, label in train_dataset:\n",
        "    train_images.append(img.numpy())\n",
        "    train_labels.append(label)\n",
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for img, label in test_dataset:\n",
        "    test_images.append(img.numpy())\n",
        "    test_labels.append(label)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DsNmS7JRlJVo"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def conv2d_forward(X, W, b, stride=1, padding=0):\n",
        "    N, C, H, W_in = X.shape\n",
        "    F, _, HH, WW = W.shape\n",
        "    out_h = (H + 2*padding - HH)//stride + 1\n",
        "    out_w = (W_in + 2*padding - WW)//stride + 1\n",
        "\n",
        "    X_pad = np.pad(X, ((0,0),(0,0),(padding,padding),(padding,padding)), mode='constant')\n",
        "    out = np.zeros((N, F, out_h, out_w))\n",
        "\n",
        "    for n in range(N):\n",
        "        for f in range(F):\n",
        "            for i in range(out_h):\n",
        "                for j in range(out_w):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    window = X_pad[n, :, h_start:h_start+HH, w_start:w_start+WW]\n",
        "                    out[n, f, i, j] = np.sum(window * W[f]) + b[f]\n",
        "    return out\n",
        "\n",
        "def relu_forward(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "def maxpool_forward(X, size=2, stride=2):\n",
        "    N, C, H, W_in = X.shape\n",
        "    out_h = (H - size)//stride + 1\n",
        "    out_w = (W_in - size)//stride + 1\n",
        "    out = np.zeros((N, C, out_h, out_w))\n",
        "\n",
        "    for n in range(N):\n",
        "        for c in range(C):\n",
        "            for i in range(out_h):\n",
        "                for j in range(out_w):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    window = X[n, c, h_start:h_start+size, w_start:w_start+size]\n",
        "                    out[n, c, i, j] = np.max(window)\n",
        "    return out\n",
        "\n",
        "def fc_forward(X, W, b):\n",
        "    return X @ W + b\n",
        "\n",
        "def softmax_crossentropy_loss(logits, labels):\n",
        "    shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "    exp_logits = np.exp(shifted_logits)\n",
        "    probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "    N = logits.shape[0]\n",
        "    loss = -np.sum(np.log(probs[np.arange(N), labels])) / N\n",
        "\n",
        "    dlogits = probs.copy()\n",
        "    dlogits[np.arange(N), labels] -= 1\n",
        "    dlogits /= N\n",
        "\n",
        "    return loss, dlogits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ATOsxzCG0nMr"
      },
      "outputs": [],
      "source": [
        "def alexnet_forward(X, params):\n",
        "    out = conv2d_forward(X, params['W1'], params['b1'], stride=1, padding=1)\n",
        "    out = relu_forward(out)\n",
        "    out = maxpool_forward(out, size=2, stride=2)\n",
        "\n",
        "    out = conv2d_forward(out, params['W2'], params['b2'], stride=1, padding=2)\n",
        "    out = relu_forward(out)\n",
        "    out = maxpool_forward(out, size=2, stride=2)\n",
        "\n",
        "    out = conv2d_forward(out, params['W3'], params['b3'], stride=1, padding=1)\n",
        "    out = relu_forward(out)\n",
        "\n",
        "    out = conv2d_forward(out, params['W4'], params['b4'], stride=1, padding=1)\n",
        "    out = relu_forward(out)\n",
        "\n",
        "    out = conv2d_forward(out, params['W5'], params['b5'], stride=1, padding=1)\n",
        "    out = relu_forward(out)\n",
        "    out = maxpool_forward(out, size=2, stride=2)\n",
        "\n",
        "    N = out.shape[0]\n",
        "    out = out.reshape(N, -1)\n",
        "\n",
        "    out = fc_forward(out, params['W6'], params['b6'])\n",
        "    out = relu_forward(out)\n",
        "\n",
        "    out = fc_forward(out, params['W7'], params['b7'])\n",
        "    out = relu_forward(out)\n",
        "\n",
        "    out = fc_forward(out, params['W8'], params['b8'])\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FqEuRVl10ySo"
      },
      "outputs": [],
      "source": [
        "def initialize_params():\n",
        "    params = {}\n",
        "    params['W1'] = np.random.randn(64, 3, 3, 3) * np.sqrt(2. / (3*3*3))\n",
        "    params['b1'] = np.zeros(64)\n",
        "    params['W2'] = np.random.randn(192, 64, 5, 5) * np.sqrt(2. / (64*5*5))\n",
        "    params['b2'] = np.zeros(192)\n",
        "    params['W3'] = np.random.randn(384, 192, 3, 3) * np.sqrt(2. / (192*3*3))\n",
        "    params['b3'] = np.zeros(384)\n",
        "    params['W4'] = np.random.randn(256, 384, 3, 3) * np.sqrt(2. / (384*3*3))\n",
        "    params['b4'] = np.zeros(256)\n",
        "    params['W5'] = np.random.randn(256, 256, 3, 3) * np.sqrt(2. / (256*3*3))\n",
        "    params['b5'] = np.zeros(256)\n",
        "    params['W6'] = np.random.randn(256*4*4, 4096) * np.sqrt(2. / (256*4*4))\n",
        "    params['b6'] = np.zeros(4096)\n",
        "    params['W7'] = np.random.randn(4096, 4096) * np.sqrt(2. / 4096)\n",
        "    params['b7'] = np.zeros(4096)\n",
        "    params['W8'] = np.random.randn(4096, 10) * np.sqrt(2. / 4096)\n",
        "    params['b8'] = np.zeros(10)\n",
        "    return params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdLoigEr0p6o",
        "outputId": "d1a34334-ae1a-4250-a4b2-7a008cdcb73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 2.6206\n"
          ]
        }
      ],
      "source": [
        "params = initialize_params()\n",
        "\n",
        "batch_X = train_images[:32]\n",
        "batch_y = train_labels[:32]\n",
        "\n",
        "logits = alexnet_forward(batch_X, params)\n",
        "\n",
        "loss, probs = softmax_crossentropy_loss(logits, batch_y)\n",
        "\n",
        "print(f\"loss = {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zf7iu4Wj_xrf"
      },
      "outputs": [],
      "source": [
        "def fc_backward(dout, X, W, b):\n",
        "    dX = dout @ W.T\n",
        "    dW = X.T @ dout\n",
        "    db = np.sum(dout, axis=0)\n",
        "    return dX, dW, db\n",
        "def relu_backward(dout, X):\n",
        "    dX = dout * (X > 0)\n",
        "    return dX\n",
        "def maxpool_backward(dout, X, size=2, stride=2):\n",
        "    N, C, H, W = X.shape\n",
        "    out_h, out_w = dout.shape[2], dout.shape[3]\n",
        "    dX = np.zeros_like(X)\n",
        "\n",
        "    for n in range(N):\n",
        "        for c in range(C):\n",
        "            for i in range(out_h):\n",
        "                for j in range(out_w):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    window = X[n, c, h_start:h_start+size, w_start:w_start+size]\n",
        "                    max_val = np.max(window)\n",
        "                    for ii in range(size):\n",
        "                        for jj in range(size):\n",
        "                            if window[ii, jj] == max_val:\n",
        "                                dX[n, c, h_start+ii, w_start+jj] += dout[n, c, i, j]\n",
        "                                break\n",
        "                        else:\n",
        "                            continue\n",
        "                        break\n",
        "    return dX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFNGEgRfKQZ_"
      },
      "outputs": [],
      "source": [
        "def conv2d_backward(dout, X, W, b, stride=1, padding=0):\n",
        "    N, C, H, W_in = X.shape\n",
        "    F, _, HH, WW = W.shape\n",
        "    out_h, out_w = dout.shape[2], dout.shape[3]\n",
        "\n",
        "    X_pad = np.pad(X, ((0,0),(0,0),(padding,padding),(padding,padding)), mode='constant')\n",
        "    dX_pad = np.zeros_like(X_pad)\n",
        "    dW = np.zeros_like(W)\n",
        "    db = np.zeros_like(b)\n",
        "\n",
        "    for n in range(N):\n",
        "        for f in range(F):\n",
        "            for i in range(out_h):\n",
        "                for j in range(out_w):\n",
        "                    h_start = i * stride\n",
        "                    w_start = j * stride\n",
        "                    window = X_pad[n, :, h_start:h_start+HH, w_start:w_start+WW]\n",
        "\n",
        "                    dW[f] += window * dout[n, f, i, j]\n",
        "\n",
        "                    dX_pad[n, :, h_start:h_start+HH, w_start:w_start+WW] += W[f] * dout[n, f, i, j]\n",
        "\n",
        "            db[f] += np.sum(dout[n, f])\n",
        "\n",
        "    if padding > 0:\n",
        "        dX = dX_pad[:, :, padding:-padding, padding:-padding]\n",
        "    else:\n",
        "        dX = dX_pad\n",
        "\n",
        "    return dX, dW, db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-UZZaJrN7cr"
      },
      "outputs": [],
      "source": [
        "def sgd_update(params, grads, learning_rate=0.01):\n",
        "    for key in params.keys():\n",
        "        params[key] -= learning_rate * grads[key]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOXXKmGTOCBT"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "params = initialize_params()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    idx = np.random.permutation(len(train_images))\n",
        "    train_images_shuffled = train_images[idx]\n",
        "    train_labels_shuffled = train_labels[idx]\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    num_batches = len(train_images) // batch_size\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "        X_batch = train_images_shuffled[i*batch_size:(i+1)*batch_size]\n",
        "        y_batch = train_labels_shuffled[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "\n",
        "        X1 = conv2d_forward(X_batch, params['W1'], params['b1'], stride=1, padding=1)\n",
        "        A1 = relu_forward(X1)\n",
        "        P1 = maxpool_forward(A1, size=2, stride=2)\n",
        "\n",
        "        X2 = conv2d_forward(P1, params['W2'], params['b2'], stride=1, padding=2)\n",
        "        A2 = relu_forward(X2)\n",
        "        P2 = maxpool_forward(A2, size=2, stride=2)\n",
        "\n",
        "        X3 = conv2d_forward(P2, params['W3'], params['b3'], stride=1, padding=1)\n",
        "        A3 = relu_forward(X3)\n",
        "\n",
        "        X4 = conv2d_forward(A3, params['W4'], params['b4'], stride=1, padding=1)\n",
        "        A4 = relu_forward(X4)\n",
        "\n",
        "        X5 = conv2d_forward(A4, params['W5'], params['b5'], stride=1, padding=1)\n",
        "        A5 = relu_forward(X5)\n",
        "        P5 = maxpool_forward(A5, size=2, stride=2)\n",
        "\n",
        "        N = P5.shape[0]\n",
        "        flatten = P5.reshape(N, -1)\n",
        "\n",
        "        FC1 = fc_forward(flatten, params['W6'], params['b6'])\n",
        "        A6 = relu_forward(FC1)\n",
        "\n",
        "        FC2 = fc_forward(A6, params['W7'], params['b7'])\n",
        "        A7 = relu_forward(FC2)\n",
        "\n",
        "        FC3 = fc_forward(A7, params['W8'], params['b8'])\n",
        "\n",
        "        loss, dFC3 = softmax_crossentropy_loss(FC3, y_batch)\n",
        "        epoch_loss += loss\n",
        "\n",
        "\n",
        "        grads = {}\n",
        "\n",
        "        dA7, grads['W8'], grads['b8'] = fc_backward(dFC3, A7, params['W8'], params['b8'])\n",
        "\n",
        "        dFC2 = relu_backward(dA7, FC2)\n",
        "\n",
        "        dA6, grads['W7'], grads['b7'] = fc_backward(dFC2, A6, params['W7'], params['b7'])\n",
        "        dFC1 = relu_backward(dA6, FC1)\n",
        "\n",
        "        dflatten, grads['W6'], grads['b6'] = fc_backward(dFC1, flatten, params['W6'], params['b6'])\n",
        "\n",
        "        dP5 = dflatten.reshape(P5.shape)\n",
        "\n",
        "        dA5 = maxpool_backward(dP5, A5, size=2, stride=2)\n",
        "\n",
        "        dX5 = relu_backward(dA5, X5)\n",
        "        dA4, grads['W5'], grads['b5'] = conv2d_backward(dX5, A4, params['W5'], params['b5'], stride=1, padding=1)\n",
        "\n",
        "        dX4 = relu_backward(dA4, X4)\n",
        "        dA3, grads['W4'], grads['b4'] = conv2d_backward(dX4, A3, params['W4'], params['b4'], stride=1, padding=1)\n",
        "\n",
        "        dX3 = relu_backward(dA3, X3)\n",
        "        dP2, grads['W3'], grads['b3'] = conv2d_backward(dX3, P2, params['W3'], params['b3'], stride=1, padding=1)\n",
        "\n",
        "        dA2 = maxpool_backward(dP2, A2, size=2, stride=2)\n",
        "\n",
        "        dX2 = relu_backward(dA2, X2)\n",
        "        dP1, grads['W2'], grads['b2'] = conv2d_backward(dX2, P1, params['W2'], params['b2'], stride=1, padding=2)\n",
        "\n",
        "        dA1 = maxpool_backward(dP1, A1, size=2, stride=2)\n",
        "\n",
        "        dX1 = relu_backward(dA1, X1)\n",
        "        dX, grads['W1'], grads['b1'] = conv2d_backward(dX1, X_batch, params['W1'], params['b1'], stride=1, padding=1)\n",
        "\n",
        "        sgd_update(params, grads, learning_rate=learning_rate)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/num_batches:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVK47NkNOuVN"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(images, labels, params, batch_size=64):\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    num_batches = len(images) // batch_size\n",
        "    for i in range(num_batches):\n",
        "        X_batch = images[i*batch_size:(i+1)*batch_size]\n",
        "        y_batch = labels[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "        X1 = conv2d_forward(X_batch, params['W1'], params['b1'], stride=1, padding=1)\n",
        "        A1 = relu_forward(X1)\n",
        "        P1 = maxpool_forward(A1, size=2, stride=2)\n",
        "\n",
        "        X2 = conv2d_forward(P1, params['W2'], params['b2'], stride=1, padding=2)\n",
        "        A2 = relu_forward(X2)\n",
        "        P2 = maxpool_forward(A2, size=2, stride=2)\n",
        "\n",
        "        X3 = conv2d_forward(P2, params['W3'], params['b3'], stride=1, padding=1)\n",
        "        A3 = relu_forward(X3)\n",
        "\n",
        "        X4 = conv2d_forward(A3, params['W4'], params['b4'], stride=1, padding=1)\n",
        "        A4 = relu_forward(X4)\n",
        "\n",
        "        X5 = conv2d_forward(A4, params['W5'], params['b5'], stride=1, padding=1)\n",
        "        A5 = relu_forward(X5)\n",
        "        P5 = maxpool_forward(A5, size=2, stride=2)\n",
        "\n",
        "        flatten = P5.reshape(P5.shape[0], -1)\n",
        "\n",
        "        FC1 = fc_forward(flatten, params['W6'], params['b6'])\n",
        "        A6 = relu_forward(FC1)\n",
        "\n",
        "        FC2 = fc_forward(A6, params['W7'], params['b7'])\n",
        "        A7 = relu_forward(FC2)\n",
        "\n",
        "        FC3 = fc_forward(A7, params['W8'], params['b8'])\n",
        "\n",
        "        preds = np.argmax(FC3, axis=1)\n",
        "\n",
        "        total_correct += np.sum(preds == y_batch)\n",
        "        total_samples += y_batch.shape[0]\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWrYVbWiOxdc"
      },
      "outputs": [],
      "source": [
        "test_acc = evaluate_accuracy(test_images, test_labels, params)\n",
        "print(f'Test Accuracy: {test_acc*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIKeHDdhEd9L"
      },
      "outputs": [],
      "source": [
        "input()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPINXgWbdRwThWN4OGyGkbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}