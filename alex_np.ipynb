{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c482a5b-d705-4288-b4db-bc1748ad1f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 3, 32, 32)\n",
      "(50000,)\n",
      "(10000, 3, 32, 32)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/', train=False, transform=transform, download=True)\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "for img, label in train_dataset:\n",
    "    train_images.append(img.numpy())\n",
    "    train_labels.append(label)\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for img, label in test_dataset:\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc35cf0-dc16-4e6a-bc91-a845f5b0cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\yudon\\anaconda3\\envs\\pytorch\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\yudon\\anaconda3\\envs\\pytorch\\lib\\site-packages (from opencv-python) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b94a8c6-7a9f-4273-8057-e15f137dd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def conv2d_forward(X, W, b, stride=1, padding=0):\n",
    "    N, C, H, W_in = X.shape\n",
    "    F, _, HH, WW = W.shape\n",
    "    out_h = (H + 2*padding - HH)//stride + 1\n",
    "    out_w = (W_in + 2*padding - WW)//stride + 1\n",
    "\n",
    "    X_pad = np.pad(X, ((0,0),(0,0),(padding,padding),(padding,padding)), mode='constant')\n",
    "    out = np.zeros((N, F, out_h, out_w))\n",
    "\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    window = X_pad[n, :, h_start:h_start+HH, w_start:w_start+WW]\n",
    "                    out[n, f, i, j] = np.sum(window * W[f]) + b[f]\n",
    "    return out\n",
    "\n",
    "def relu_forward(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def maxpool_forward(X, size=2, stride=2):\n",
    "    N, C, H, W_in = X.shape\n",
    "    out_h = (H - size)//stride + 1\n",
    "    out_w = (W_in - size)//stride + 1\n",
    "    out = np.zeros((N, C, out_h, out_w))\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    window = X[n, c, h_start:h_start+size, w_start:w_start+size]\n",
    "                    out[n, c, i, j] = np.max(window)\n",
    "    return out\n",
    "\n",
    "def fc_forward(X, W, b):\n",
    "    return X @ W + b\n",
    "\n",
    "def softmax_crossentropy_loss(logits, labels):\n",
    "    shifted_logits = logits - np.max(logits, axis=1, keepdims=True)\n",
    "    exp_logits = np.exp(shifted_logits)\n",
    "    probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "    N = logits.shape[0]\n",
    "    loss = -np.sum(np.log(probs[np.arange(N), labels])) / N\n",
    "\n",
    "    dlogits = probs.copy()\n",
    "    dlogits[np.arange(N), labels] -= 1\n",
    "    dlogits /= N\n",
    "\n",
    "    return loss, dlogits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ed10f3-b502-49ae-9509-c47b2d2d1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_forward(X, params):\n",
    "    out = conv2d_forward(X, params['W1'], params['b1'], stride=1, padding=1)\n",
    "    out = relu_forward(out)\n",
    "    out = maxpool_forward(out, size=2, stride=2)\n",
    "\n",
    "    out = conv2d_forward(out, params['W2'], params['b2'], stride=1, padding=2)\n",
    "    out = relu_forward(out)\n",
    "    out = maxpool_forward(out, size=2, stride=2)\n",
    "\n",
    "    out = conv2d_forward(out, params['W3'], params['b3'], stride=1, padding=1)\n",
    "    out = relu_forward(out)\n",
    "\n",
    "    out = conv2d_forward(out, params['W4'], params['b4'], stride=1, padding=1)\n",
    "    out = relu_forward(out)\n",
    "\n",
    "    out = conv2d_forward(out, params['W5'], params['b5'], stride=1, padding=1)\n",
    "    out = relu_forward(out)\n",
    "    out = maxpool_forward(out, size=2, stride=2)\n",
    "\n",
    "    N = out.shape[0]\n",
    "    out = out.reshape(N, -1)\n",
    "\n",
    "    out = fc_forward(out, params['W6'], params['b6'])\n",
    "    out = relu_forward(out)\n",
    "\n",
    "    out = fc_forward(out, params['W7'], params['b7'])\n",
    "    out = relu_forward(out)\n",
    "\n",
    "    out = fc_forward(out, params['W8'], params['b8'])\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb52503-4f62-4a9b-a0ab-bbd4bb864c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params():\n",
    "    params = {}\n",
    "    params['W1'] = np.random.randn(64, 3, 3, 3) * np.sqrt(2. / (3*3*3))\n",
    "    params['b1'] = np.zeros(64)\n",
    "    params['W2'] = np.random.randn(192, 64, 5, 5) * np.sqrt(2. / (64*5*5))\n",
    "    params['b2'] = np.zeros(192)\n",
    "    params['W3'] = np.random.randn(384, 192, 3, 3) * np.sqrt(2. / (192*3*3))\n",
    "    params['b3'] = np.zeros(384)\n",
    "    params['W4'] = np.random.randn(256, 384, 3, 3) * np.sqrt(2. / (384*3*3))\n",
    "    params['b4'] = np.zeros(256)\n",
    "    params['W5'] = np.random.randn(256, 256, 3, 3) * np.sqrt(2. / (256*3*3))\n",
    "    params['b5'] = np.zeros(256)\n",
    "    params['W6'] = np.random.randn(256*4*4, 4096) * np.sqrt(2. / (256*4*4))\n",
    "    params['b6'] = np.zeros(4096)\n",
    "    params['W7'] = np.random.randn(4096, 4096) * np.sqrt(2. / 4096)\n",
    "    params['b7'] = np.zeros(4096)\n",
    "    params['W8'] = np.random.randn(4096, 10) * np.sqrt(2. / 4096)\n",
    "    params['b8'] = np.zeros(10)\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af55c6-cf76-49e5-a705-39ab5d870ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initialize_params()\n",
    "\n",
    "batch_X = train_images[:32]\n",
    "batch_y = train_labels[:32]\n",
    "\n",
    "logits = alexnet_forward(batch_X, params)\n",
    "\n",
    "loss, probs = softmax_crossentropy_loss(logits, batch_y)\n",
    "\n",
    "print(f\"loss = {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460f8cad-c0e1-4f3e-88f6-dcaaf8344352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_backward(dout, X, W, b):\n",
    "    dX = dout @ W.T\n",
    "    dW = X.T @ dout\n",
    "    db = np.sum(dout, axis=0)\n",
    "    return dX, dW, db\n",
    "def relu_backward(dout, X):\n",
    "    dX = dout * (X > 0)\n",
    "    return dX\n",
    "def maxpool_backward(dout, X, size=2, stride=2):\n",
    "    N, C, H, W = X.shape\n",
    "    out_h, out_w = dout.shape[2], dout.shape[3]\n",
    "    dX = np.zeros_like(X)\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    window = X[n, c, h_start:h_start+size, w_start:w_start+size]\n",
    "                    max_val = np.max(window)\n",
    "                    for ii in range(size):\n",
    "                        for jj in range(size):\n",
    "                            if window[ii, jj] == max_val:\n",
    "                                dX[n, c, h_start+ii, w_start+jj] += dout[n, c, i, j]\n",
    "                                break\n",
    "                        else:\n",
    "                            continue\n",
    "                        break\n",
    "    return dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec1de9a-e22f-445b-8c59-cc364335ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_backward(dout, X, W, b, stride=1, padding=0):\n",
    "    N, C, H, W_in = X.shape\n",
    "    F, _, HH, WW = W.shape\n",
    "    out_h, out_w = dout.shape[2], dout.shape[3]\n",
    "\n",
    "    X_pad = np.pad(X, ((0,0),(0,0),(padding,padding),(padding,padding)), mode='constant')\n",
    "    dX_pad = np.zeros_like(X_pad)\n",
    "    dW = np.zeros_like(W)\n",
    "    db = np.zeros_like(b)\n",
    "\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    h_start = i * stride\n",
    "                    w_start = j * stride\n",
    "                    window = X_pad[n, :, h_start:h_start+HH, w_start:w_start+WW]\n",
    "\n",
    "                    dW[f] += window * dout[n, f, i, j]\n",
    "\n",
    "                    dX_pad[n, :, h_start:h_start+HH, w_start:w_start+WW] += W[f] * dout[n, f, i, j]\n",
    "\n",
    "            db[f] += np.sum(dout[n, f])\n",
    "\n",
    "    if padding > 0:\n",
    "        dX = dX_pad[:, :, padding:-padding, padding:-padding]\n",
    "    else:\n",
    "        dX = dX_pad\n",
    "\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c60879-bce6-4b5c-9c59-73662774102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(params, grads, learning_rate=0.01):\n",
    "    for key in params.keys():\n",
    "        params[key] -= learning_rate * grads[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466318e-9871-461f-8f0c-0125bee58915",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "params = initialize_params()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    idx = np.random.permutation(len(train_images))\n",
    "    train_images_shuffled = train_images[idx]\n",
    "    train_labels_shuffled = train_labels[idx]\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = len(train_images) // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        X_batch = train_images_shuffled[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = train_labels_shuffled[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # Forward\n",
    "        X1 = conv2d_forward(X_batch, params['W1'], params['b1'], stride=1, padding=1)\n",
    "        A1 = relu_forward(X1)\n",
    "        P1 = maxpool_forward(A1, size=2, stride=2)\n",
    "\n",
    "        X2 = conv2d_forward(P1, params['W2'], params['b2'], stride=1, padding=2)\n",
    "        A2 = relu_forward(X2)\n",
    "        P2 = maxpool_forward(A2, size=2, stride=2)\n",
    "\n",
    "        X3 = conv2d_forward(P2, params['W3'], params['b3'], stride=1, padding=1)\n",
    "        A3 = relu_forward(X3)\n",
    "\n",
    "        X4 = conv2d_forward(A3, params['W4'], params['b4'], stride=1, padding=1)\n",
    "        A4 = relu_forward(X4)\n",
    "\n",
    "        X5 = conv2d_forward(A4, params['W5'], params['b5'], stride=1, padding=1)\n",
    "        A5 = relu_forward(X5)\n",
    "        P5 = maxpool_forward(A5, size=2, stride=2)\n",
    "\n",
    "        N = P5.shape[0]\n",
    "        flatten = P5.reshape(N, -1)\n",
    "\n",
    "        FC1 = fc_forward(flatten, params['W6'], params['b6'])\n",
    "        A6 = relu_forward(FC1)\n",
    "\n",
    "        FC2 = fc_forward(A6, params['W7'], params['b7'])\n",
    "        A7 = relu_forward(FC2)\n",
    "\n",
    "        FC3 = fc_forward(A7, params['W8'], params['b8'])\n",
    "\n",
    "        # Loss and backward\n",
    "        loss, dFC3 = softmax_crossentropy_loss(FC3, y_batch)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        grads = {}\n",
    "\n",
    "        dA7, grads['W8'], grads['b8'] = fc_backward(dFC3, A7, params['W8'], params['b8'])\n",
    "        dFC2 = relu_backward(dA7, FC2)\n",
    "        dA6, grads['W7'], grads['b7'] = fc_backward(dFC2, A6, params['W7'], params['b7'])\n",
    "        dFC1 = relu_backward(dA6, FC1)\n",
    "        dflatten, grads['W6'], grads['b6'] = fc_backward(dFC1, flatten, params['W6'], params['b6'])\n",
    "\n",
    "        dP5 = dflatten.reshape(P5.shape)\n",
    "        dA5 = maxpool_backward(dP5, A5, size=2, stride=2)\n",
    "\n",
    "        dX5 = relu_backward(dA5, X5)\n",
    "        dA4, grads['W5'], grads['b5'] = conv2d_backward(dX5, A4, params['W5'], params['b5'], stride=1, padding=1)\n",
    "\n",
    "        dX4 = relu_backward(dA4, X4)\n",
    "        dA3, grads['W4'], grads['b4'] = conv2d_backward(dX4, A3, params['W4'], params['b4'], stride=1, padding=1)\n",
    "\n",
    "        dX3 = relu_backward(dA3, X3)\n",
    "        dP2, grads['W3'], grads['b3'] = conv2d_backward(dX3, P2, params['W3'], params['b3'], stride=1, padding=1)\n",
    "\n",
    "        dA2 = maxpool_backward(dP2, A2, size=2, stride=2)\n",
    "\n",
    "        dX2 = relu_backward(dA2, X2)\n",
    "        dP1, grads['W2'], grads['b2'] = conv2d_backward(dX2, P1, params['W2'], params['b2'], stride=1, padding=2)\n",
    "\n",
    "        dA1 = maxpool_backward(dP1, A1, size=2, stride=2)\n",
    "\n",
    "        dX1 = relu_backward(dA1, X1)\n",
    "        dX, grads['W1'], grads['b1'] = conv2d_backward(dX1, X_batch, params['W1'], params['b1'], stride=1, padding=1)\n",
    "\n",
    "        sgd_update(params, grads, learning_rate=learning_rate)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs} - Batch {i+1}/{num_batches}')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss/num_batches:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974df06-6c87-49c3-9dfb-451290abac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ファイルから読み込む\n",
    "loaded = np.load(\"saved_params.npz\")\n",
    "\n",
    "# params 辞書を復元\n",
    "params = {k: loaded[k] for k in loaded.files}\n",
    "\n",
    "print(\"✅ パラメータを復元しました！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f9e269-8cc3-43c6-81e4-81d7d7141f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ パラメータ保存完了\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 学習パラメータを保存\n",
    "params_np = {k: v for k, v in params.items()}  # NumPy版なのでそのまま\n",
    "np.savez(\"saved_params.npz\", **params_np)\n",
    "print(\"✅ パラメータ保存完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d477dbb6-dc00-4668-87f8-b551f3a761e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4', 'W5', 'b5', 'W6', 'b6', 'W7', 'b7', 'W8', 'b8']\n"
     ]
    }
   ],
   "source": [
    "loaded = np.load(\"saved_params.npz\", allow_pickle=False)\n",
    "print(loaded.files)  # 含まれるキーだけ確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99b1a3d-f353-4ef4-b455-c38c693d8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(\"saved_params.npz\", mmap_mode='r')\n",
    "params = {k: loaded[k] for k in loaded.files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e8052-12fe-4214-aa7f-8dc46bfc6314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
